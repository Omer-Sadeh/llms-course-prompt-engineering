{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering Experiment Analysis\n",
    "\n",
    "This notebook analyzes the results of various prompt engineering strategies applied to logic puzzles (syllogisms).\n",
    "\n",
    "## Strategies Tested\n",
    "1. **Baseline**: Zero-shot prompting.\n",
    "2. **Basic**: System message instruction.\n",
    "3. **Few-Shot**: Providing examples.\n",
    "4. **Chain of Thought**: Asking for step-by-step reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from src.config.config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Results\n",
    "results_path = Path('../results/experiment_results.csv')\n",
    "\n",
    "if results_path.exists():\n",
    "    df = pd.read_csv(results_path)\n",
    "    print(f\"Loaded {len(df)} rows.\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"No results found. Run `python src/main.py` first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Summary\n",
    "We calculate the mean and standard deviation of the vector distance (cosine distance) for each strategy. Lower distance implies the model output is semantically closer to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    summary = df.groupby('strategy')['vector_distance'].agg(['mean', 'std', 'count']).sort_values('mean')\n",
    "    display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology & References\n",
    "\n",
    "### Metric: Cosine Distance\n",
    "We measure the semantic similarity using Cosine Distance, defined as:\n",
    "$$\n",
    "\\text{Cosine Distance}(A, B) = 1 - \text{Cosine Similarity}(A, B) = 1 - \frac{A \\cdot B}{\\ \\|A\\| \\ \\|B\\|}",
    "$$\n",
    "where $A$ and $B$ are the embedding vectors of the model output and ground truth, respectively.\n",
    "\n",
    "### Extended References & Methodology Context\n",
    "\n",
    "#### 1. Fundamental Architectures\n",
    "- **Transformer Models**: Vaswani, A., et al. (2017). \"Attention Is All You Need\". [arXiv:1706.03762](https://arxiv.org/abs/1706.03762). This work establishes the foundation for the LLMs used in this study.\n",
    "\n",
    "#### 2. Prompting Strategies\n",
    "- **Chain of Thought (CoT)**: Wei, J., et al. (2022). \"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models\". [arXiv:2201.11903](https://arxiv.org/abs/2201.11903). Justifies our use of step-by-step reasoning triggers for logic puzzles.\n",
    "- **Few-Shot Learning**: Brown, T., et al. (2020). \"Language Models are Few-Shot Learners\". [arXiv:2005.14165](https://arxiv.org/abs/2005.14165). Provides the theoretical basis for our few-shot strategy.\n",
    "- **Zero-Shot Reasoning**: Kojima, T., et al. (2022). \"Large Language Models are Zero-Shot Reasoners\". [arXiv:2205.11916](https://arxiv.org/abs/2205.11916). Supports our baseline and basic prompting approaches.\n",
    "- **Self-Consistency**: Wang, X., et al. (2022). \"Self-Consistency Improves Chain of Thought Reasoning in Language Models\". [arXiv:2203.11171](https://arxiv.org/abs/2203.11171). Relevant for future work in ensemble methods.\n",
    "\n",
    "#### 3. Semantic Evaluation\n",
    "- **Sentence Embeddings**: Reimers, N., & Gurevych, I. (2019). \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\". [arXiv:1908.10084](https://arxiv.org/abs/1908.10084). Justifies our choice of SBERT (all-MiniLM-L6-v2) for measuring semantic similarity (Cosine Distance) over exact string matching, which is often too brittle for generative tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=df, x='strategy', y='vector_distance', palette='viridis')\n",
    "    plt.title('Mean Vector Distance by Strategy')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/figures/results_plot_high_res.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}